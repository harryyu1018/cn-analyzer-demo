# cn-analyzer-demo
对主流中文分词开源工具进行分词效果和性能对比的项目

## 主流的开源中文分词工具
- [HanLP](https://github.com/hankcs/HanLP)  由一系列模型与算法组成的Java工具包，目标是普及自然语言处理在生产环境中的应用
- [Ansj](https://github.com/NLPchina/ansj_seg)  基于n-Gram+CRF+HMM的中文分词java实现
- [mmseg4j](https://github.com/chenlb/mmseg4j-core) 基于Chih-Hao Tsai的[MMSeg算法](http://technology.chtsai.org/mmseg/)实现的中文分词
- [word](https://github.com/ysc/word)   是一个java实现的分布式的中文分词组件，提供了多种基于词典的分词算法，并利用ngram模型消除歧义。
- [jcseg](https://git.oschina.net/lionsoul/jcseg)   是基于mmseg算法的一个轻量级中文分词器，同时集成了关键字提取，关键句子提取和文章自动摘要等功能

